str(df)
df_split <- initial_split(df)
train_data <- training(df_split)
test_data <- testing(df_split)
cv_train <- vfold_cv(train_data, v = 5, repeats = 2, strata = out)
standardized <- recipe(diabetes ~ ., data = train_data)%>%
step_center(all_predictors())  %>%
step_scale(all_predictors()) %>%
themis::step_smote (diabetes)
train_preped <- prep(standardized) %>%
bake(new_data = NULL)
test_preped <-  prep(standardized) %>%
bake(new_data = test_data)
require(doParallel)
cores <- parallel::detectCores(logical = FALSE)
registerDoParallel(cores = cores)
Y_train <- train_preped$diabetes
x_train <- train_preped[ , -c(train_preped)]
x_train <- train_preped[ , -c(diabetes)]
x_train <- train_preped[ , -c("diabetes")]
View(train_preped)
x_train <- train_preped[ , -9]
# Let's build models
library("randomForest")
set.seed(123)
model_rf <- randomForest(x = x_train, y = Y_train)
# here shapper starts
# load shapper
library(shapper)
p_function <- function(model, data) predict(model, newdata = data, type = "prob")
ive_rf <- individual_variable_effect(model_rf, data = x_train, predict_function = p_function,
new_observation = x_train[1:2,], nsamples = 50)
# plot
plot(ive_rf)
# Prepare the data for explanation
explainer <- shapr(train_preped, pp$fit)
local_obs <- train_preped[1:5, ]
model_rf
# Prepare the data for explanation
explainer <- shapr(train_preped, model_rf)
# Prepare the data for explanation
explainer <- shapr(train_preped, model_rf$fit)
pp=set_engine("ranger", importance = "permutation") %>%
fit(diabetes ~ .,
data = train_preped
)
rf_mod <-
rand_forest(mtry = tune(), min_n = tune(), trees = tune()) %>%
set_engine("ranger", num.threads = cores) %>%
set_mode("classification")
rf_mod
rf_workflow <-
workflow() %>%
add_model(rf_mod) %>%
add_recipe(standardized)
rf_workflow
set.seed(345)
rf_res <-
rf_workflow %>%
tune_grid(grid = 100,
control = control_stack_grid(),
metrics = metric_set(roc_auc,f_meas,sens,bal_accuracy),
resamples = cv_train)
rf_res %>%
collect_metrics()
rf_best <-
rf_res %>%
select_best(metric = "f_meas")
rf_best
rf_res %>%
show_best(metric = "f_meas")
autoplot(rf_res)
final_rf <- finalize_model(
rf_mod,
rf_best
)
final_rf
pp=final_rf %>%
set_engine("ranger", importance = "permutation") %>%
fit(diabetes ~ .,
data = train_preped
)
local_obs <- train_preped[1:5, ]
explainer_caret <- lime(train_preped, pp$fit, n_bins = 2)
class(explainer_caret)
summary(explainer_caret)
explanation_caret <- explain(
x = local_obs,
explainer = explainer_caret,
n_permutations = 10000,
approach = "empirical",
dist_fun = "gower",
kernel_width = .75,
n_features = 5,
labels = "diabetes"
)
explanation_caret <- explain(
x = local_obs,
explainer = explainer_caret,
n_permutations = 10000,
approach = "empirical",
dist_fun = "gower",
kernel_width = .75,
n_features = 5,
labels = "pos"
)
explainer_caret <- lime(train_preped, pp$fit)
class(explainer_caret)
summary(explainer_caret)
explanation_caret <- explain(
x = local_obs,
explainer = explainer_caret,
n_permutations = 10000,
approach = "empirical",
dist_fun = "gower",
kernel_width = .75,
n_features = 5,
labels = "pos"
)
explanation_caret <- explain(
x = local_obs,
explainer = explainer_caret
)
explanation_caret <- explain(
x = local_obs,
explainer = explainer_caret,
n_permutations = 10000,
approach = "empirical"
)
plot_features(explanation_caret)
# Prepare the data for explanation
explainer <- shapr(train_preped, pp$fit)
# Specifying the phi_0, i.e. the expected prediction without any features
p <- mean(train_preped)
# Prepare the data for explanation
explainer <- shapr(x_train, pp$fit)
# Specifying the phi_0, i.e. the expected prediction without any features
p <- mean(train_preped)
# Specifying the phi_0, i.e. the expected prediction without any features
p <- mean(x_train)
# Computing the actual Shapley values with kernelSHAP accounting for feature dependence using
# the empirical (conditional) distribution approach with bandwidth parameter sigma = 0.1 (default)
explanation <- explain(
x_test,
approach = "empirical",
explainer = explainer,
prediction_zero = p
)
x_train <- as.matrix(train_preped[-1:-6, 1:8])
View(x_train)
x_train <- as.matrix(train_preped[-1:-6, 1:8])
y_train <- Boston[-1:-6, 9]
x_train <- as.matrix(train_preped[-1:-6, 1:8])
y_train <- train_preped[-1:-6, 9]
x_test <- as.matrix(train_preped[1:6, 1:8])
explainer <- shapr(x_train, pp$fit)
# Specifying the phi_0, i.e. the expected prediction without any features
p <- mean(y_train)
p
y_train
# Specifying the phi_0, i.e. the expected prediction without any features
p <- mean(as.numeric(y_train))
as.numeric(y_train))
mean(as.numeric(y_train))
as.numeric(y_train)
as.numeric(c(y_train))
y_train <- as.matrix(train_preped[-1:-6, 9])
as.numeric(as.factor(y_train))
as.numeric(as.factor(y_train))-1
# Specifying the phi_0, i.e. the expected prediction without any features
p <- mean(as.numeric(as.factor(y_train))-1)
# Computing the actual Shapley values with kernelSHAP accounting for feature dependence using
# the empirical (conditional) distribution approach with bandwidth parameter sigma = 0.1 (default)
explanation <- explain(
x_test,
approach = "empirical",
explainer = explainer,
prediction_zero = p
)
# Printing the Shapley values for the test data.
# For more information about the interpretation of the values in the table, see ?shapr::explain.
print(explanation$dt)
plot(explanation, plot_phi0 = FALSE, index_x_test = c(1, 6))
explainer <- lime(x_train, pp$fit, bin_continuous = TRUE, quantile_bins = FALSE)
explainer <- lime(as.data.frame(x_train), pp$fit, bin_continuous = TRUE, quantile_bins = FALSE)
explanation <- explain(as.data.frame(x_test), explainer, n_labels = 1, n_features = 4)
# Only showing part of output for better printing
explanation[, 2:9]
explanation <- explain(as.data.frame(x_test), approach = "empirical", explainer, n_labels = 1, n_features = 4)
explainer <- lime(as.data.frame(x_train), pp$fit, bin_continuous = TRUE, quantile_bins = FALSE)
explanation <- explain(as.data.frame(x_test), explainer, n_labels = 1, n_features = 4)
explanation <- lime::explain(as.data.frame(x_test), explainer, n_labels = 1, n_features = 4)
# Only showing part of output for better printing
explanation[, 2:9]
plot_features(explanation, ncol = 1)
explainer <- lime(as.data.frame(x_train), pp$fit, bin_continuous = TRUE, quantile_bins = FALSE)
explanation <- lime::explain(as.data.frame(x_test), explainer, n_labels = 1, n_features = 4)
# Only showing part of output for better printing
explanation[, 2:9]
plot_features(explanation, ncol = 1)
explainer <- lime(as.data.frame(x_train), pp$fit, bin_continuous = TRUE, quantile_bins = FALSE)
explanation <- lime::explain(as.data.frame(x_test), explainer, n_labels = 1, n_features = 4)
plot_features(explanation, ncol = 1)
x_train <- as.matrix(train_preped[-1:-6, 1:8])
y_train <- as.matrix(train_preped[-1:-6, 9])
x_test <- as.matrix(train_preped[1:6, 1:8])
explainer <- shapr(x_train, pp$fit)
p <- mean(as.numeric(as.factor(y_train))-1)
explanation <- explain(
x_test,
approach = "empirical",
explainer = explainer,
prediction_zero = p
)
plot(explanation, plot_phi0 = FALSE, index_x_test = c(1, 6))
partial(pp$fit, pred.var = features[1],train=train_preped, ice = TRUE)%>%autoplot()
final_res <- rf_workflow %>%
finalize_workflow(rf_best) %>%
last_fit(df_split)
final_fitted <- final_res$.workflow[[1]]
rf_explainer <- explain_tidymodels(
final_fitted,
data = dplyr::select(train_preped, -diabetes),
y = as.integer(train_preped$diabetes),
verbose = FALSE
)
pdp_DBT<- model_profile(
rf_explainer,
variables = "mass",
N = NULL
)
pdp_DBT
as_tibble(pdp_DBT$agr_profiles) %>%
mutate(`_label_` = str_remove(`_label_`, "workflow_")) %>%
ggplot(aes(`_x_`, `_yhat_`, color = `_label_`)) +
geom_line(size = 1.2, alpha = 0.8)
pp=final_rf %>%
set_engine("ranger", importance = "permutation") %>%
fit(diabetes ~ .,
data = train_preped
)
features <- setdiff(names(train_preped), "diabetes")
pdps <- lapply(features, FUN = function(feature) {
pd <- partial(pp$fit, pred.var = feature,train=train_preped)
autoplot(pd) +
theme_light()
})
grid.arrange(grobs = pdps, ncol = 5)
features <- setdiff(names(train_preped), "diabetes")
ices <- lapply(features, FUN = function(feature) {
ice <- partial(pp$fit, pred.var = feature,train=train_preped, ice = TRUE)
autoplot(ice) +
theme_light()
})
grid.arrange(grobs = ices, ncol = 5)
final_res <- rf_workflow %>%
finalize_workflow(rf_best) %>%
last_fit(df_split)
final_fitted <- final_res$.workflow[[1]]
rf_explainer <- explain_tidymodels(
final_fitted,
data = dplyr::select(train_preped, -diabetes),
y = as.integer(train_preped$diabetes),
verbose = FALSE
)
library(tidyverse)
seq(-3,3,by=.01) %>%
expand.grid(x=., y=.) %>%
ggplot(aes(x=(x^3+sin(x)), y=(y^3-cos(y)))) +
geom_point(alpha=.1, shape=20, size=0)+
theme_void()+
coord_polar()
seq(-3,3,by=.05) %>%
expand.grid(x=., y=.) %>%
ggplot(aes(x=(x^3+sin(x)), y=(y^3-cos(y)))) +
geom_point(alpha=.1, shape=20, size=0)+
theme_void()+
coord_polar()
seq(-3,3,by=.005) %>%
expand.grid(x=., y=.) %>%
ggplot(aes(x=(x^3+sin(x)), y=(y^3-cos(y)))) +
geom_point(alpha=.1, shape=20, size=0)+
theme_void()+
coord_polar()
seq(-3,3,by=.01) %>%
expand.grid(x=., y=.) %>%
ggplot(aes(x=(x^2+sin(x)), y=(y^3-cos(y)))) +
geom_point(alpha=.1, shape=20, size=0)+
theme_void()+
coord_polar()
seq(-3,3,by=.01) %>%
expand.grid(x=., y=.) %>%
ggplot(aes(x=(x^2+sin(x)), y=(y^5-cos(y)))) +
geom_point(alpha=.1, shape=20, size=0)+
theme_void()+
coord_polar()
seq(-3,3,by=.01) %>%
expand.grid(x=., y=.) %>%
ggplot(aes(x=(x^3+sin(x)), y=(y^2-cos(y)))) +
geom_point(alpha=.1, shape=20, size=0)+
theme_void()+
coord_polar()
seq(-3,3,by=.01) %>%
expand.grid(x=., y=.) %>%
ggplot(aes(x=(x^3+sin(x)), y=(y^3-cos(y)))) +
geom_point(alpha=.1, shape=20, size=0)+
theme_void()+
coord_polar()
tibble(x=accumulate(1:230,~.x+((0.98)^.y)*cos(.y*(pi/2)^1.015),.init=0),y=accumulate(1:230,~.x+((0.98)^.y)*sin(.y*(pi/2)^1.015),.init=0)) %>% ggplot(aes(x,y)) + geom_polygon() + coord_equal() + theme_void()
tibble(x=accumulate(1:230,~.x+((0.98)^.y)*cos(.y*(pi/2)^1.015),.init=0),y=accumulate(1:230,~.x+((0.98)^.y)*sin(.y*(pi/2)^1.015),.init=0)) %>% ggplot(aes(x,y)) + geom_polygon() + coord_equal() + theme_void()
tibble(x=accumulate(1:230,~.x+((0.98)^.y)*cos(.y*(pi/2)^1.015),.init=0),y=accumulate(1:230,~.x+((0.98)^.y)*sin(.y*(pi/2)^1.015),.init=0))
%>% ggplot(aes(x,y)) + geom_polygon() + coord_equal() + theme_void()
tibble(x=accumulate(1:230,~.x+((0.98)^.y)*cos(.y*(pi/2)^1.015),.init=0),y=accumulate(1:230,~.x+((0.98)^.y)*sin(.y*(pi/2)^1.015),.init=0))%>%
ggplot(aes(x,y)) + geom_polygon() + coord_equal() + theme_void()
setwd(paste(dirname(rstudioapi::getActiveDocumentContext()$path),"",sep = ""))
load("~/OneDrive - Universite de Montreal/Usydney/data_04_2021.RData")
library(haven)
library(tidyverse)
library(tidymodels)
library(stacks)
library(vip)
library(pdp)
library(sparkline)
library(plotly)
table(Data_merged$HU_1YR)
out="HU_1YR"
df=Data_merged%>%
select(c(out,preds))%>%
drop_na()
Out_Comes
preds
library(tidyverse)
library(tidymodels)
library(stacks)
library(vip)
library(pdp)
library(sparkline)
library(plotly)
library(readr)
library(DALEX)
library(DALEXtra)
library(lime)
library(shapr)
data(pima, package = "pdp")
out="diabetes"
preds=colnames(pima)[-c(9)]
df=pima%>%
select(c(out,preds))%>%
drop_na()
table(df$diabetes)
str(df)
data(pima, package = "pdp")
out="diabetes"
preds=colnames(pima)[-c(9)]
df=pima%>%
select(c(out,preds))%>%
drop_na()
table(df$diabetes)
df_split <- initial_split(df)
train_data <- training(df_split)
test_data <- testing(df_split)
cv_train <- vfold_cv(train_data, v = 5, repeats = 2, strata = out)
standardized <- recipe(diabetes ~ ., data = train_data)%>%
step_center(all_predictors())  %>%
step_scale(all_predictors()) %>%
themis::step_smote (diabetes)
train_preped <- prep(standardized) %>%
bake(new_data = NULL)
test_preped <-  prep(standardized) %>%
bake(new_data = test_data)
require(doParallel)
cores <- parallel::detectCores(logical = FALSE)
registerDoParallel(cores = cores)
rf_mod <-
rand_forest(mtry = tune(), min_n = tune(), trees = tune()) %>%
set_engine("ranger", num.threads = cores) %>%
set_mode("classification")
rf_mod
rf_workflow <-
workflow() %>%
add_model(rf_mod) %>%
add_recipe(standardized)
rf_workflow
set.seed(345)
rf_res <-
rf_workflow %>%
tune_grid(grid = 10,
control = control_stack_grid(),
metrics = metric_set(roc_auc,f_meas,sens,bal_accuracy),
resamples = cv_train)
rf_res %>%
collect_metrics()
rf_best <-
rf_res %>%
select_best(metric = "f_meas")
rf_best
rf_res %>%
show_best(metric = "f_meas")
autoplot(rf_res)
final_rf <- finalize_model(
rf_mod,
rf_best
)
final_rf
final_rf %>%
set_engine("ranger", importance = "impurity") %>%
fit(diabetes ~ .,
data = train_preped
) %>%
vi()%>%mutate(rank = dense_rank(desc(Importance)),
mod="rf")%>% select(Variable,rank,mod)
pfun <- function(object, newdata) predict(object, data = newdata)$predictions
vips=final_rf %>%
set_engine("ranger", importance = "impurity") %>%
fit(diabetes ~ .,
data = train_preped
) %>%
vi(method = "permute", nsim = 100, target = "diabetes",
pred_wrapper = pfun, metric = "accuracy",
all_permutations = TRUE, train = train_preped)
final_rf %>%
set_engine("ranger", importance = "permutation") %>%
fit(diabetes ~ .,
data = train_preped
) %>%vip( method = "firm",feature_names = setdiff(names(train_preped), "outcome"), train = train_preped)
final_res <- rf_workflow %>%
finalize_workflow(rf_best) %>%
last_fit(df_split)
final_fitted <- final_res$.workflow[[1]]
rf_explainer <- explain_tidymodels(
final_fitted,
data = dplyr::select(train_preped, -diabetes),
y = as.integer(train_preped$diabetes),
verbose = FALSE
)
pdp_DBT<- model_profile(
rf_explainer,
variables = "mass",
N = NULL
)
pdp_DBT
as_tibble(pdp_DBT$agr_profiles) %>%
mutate(`_label_` = str_remove(`_label_`, "workflow_")) %>%
ggplot(aes(`_x_`, `_yhat_`, color = `_label_`)) +
geom_line(size = 1.2, alpha = 0.8)
pp=final_rf %>%
set_engine("ranger", importance = "permutation") %>%
fit(diabetes ~ .,
data = train_preped
)
features <- setdiff(names(train_preped), "diabetes")
pdps <- lapply(features, FUN = function(feature) {
pd <- partial(pp$fit, pred.var = feature,train=train_preped)
autoplot(pd) +
theme_light()
})
grid.arrange(grobs = pdps, ncol = 5)
pdp_DBT<- model_profile(
rf_explainer,
variables = "mass",
N = NULL
)
# pdp_DBT
#
#
# as_tibble(pdp_DBT$agr_profiles) %>%
#   mutate(`_label_` = str_remove(`_label_`, "workflow_")) %>%
#   ggplot(aes(`_x_`, `_yhat_`, color = `_label_`)) +
#   geom_line(size = 1.2, alpha = 0.8)
pp=final_rf %>%
set_engine("ranger", importance = "permutation") %>%
fit(diabetes ~ .,
data = train_preped
)
features <- setdiff(names(train_preped), "diabetes")
pdps <- lapply(features, FUN = function(feature) {
pd <- partial(pp$fit, pred.var = feature,train=train_preped)
autoplot(pd) +
theme_light()
})
grid.arrange(grobs = pdps, ncol = 5)
features <- setdiff(names(train_preped), "diabetes")
ices <- lapply(features, FUN = function(feature) {
ice <- partial(pp$fit, pred.var = feature,train=train_preped, ice = TRUE)
autoplot(ice) +
theme_light()
})
grid.arrange(grobs = ices, ncol = 5)
x_train <- as.matrix(train_preped[-1:-6, 1:8])
y_train <- as.matrix(train_preped[-1:-6, 9])
x_test <- as.matrix(train_preped[1:6, 1:8])
explainer <- shapr(x_train, pp$fit)
p <- mean(as.numeric(as.factor(y_train))-1)
explanation <- explain(
x_test,
approach = "empirical",
explainer = explainer,
prediction_zero = p
)
plot(explanation, plot_phi0 = FALSE, index_x_test = c(1, 6))
explainer <- lime(as.data.frame(x_train), pp$fit, bin_continuous = TRUE, quantile_bins = FALSE)
explanation <- lime::explain(as.data.frame(x_test), explainer, n_labels = 1, n_features = 4)
plot_features(explanation, ncol = 1)
explainer <- lime(as.data.frame(x_train), pp$fit, bin_continuous = TRUE, quantile_bins = FALSE)
explanation <- lime::explain(as.data.frame(x_test), explainer, n_labels = 1, n_features = 3)
plot_features(explanation, ncol = 1)
explainer <- lime(as.data.frame(x_train), pp$fit, bin_continuous = TRUE, quantile_bins = FALSE)
explanation <- lime::explain(as.data.frame(x_test), explainer, n_labels = 1, n_features = 3)
plot_features(explanation, ncol = 2)
explainer <- lime(as.data.frame(x_train), pp$fit, bin_continuous = TRUE, quantile_bins = FALSE)
explanation <- lime::explain(as.data.frame(x_test), explainer, n_labels = 1, n_features = 4)
plot_features(explanation, ncol = 3)
